\documentclass[smallheadings]{scrartcl}

%%% GENERAL PACKAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% inputenc allows the usage of non-ascii characters in the LaTeX source code
\usepackage[utf8]{inputenc}
\usepackage{graphicx}


% title of the document
\title{LGS mit LU Zerlegung}
% optional subtitle
%\subtitle{Draft from~\today}
% information about the author
\author{%
 Aron Ventura und Annika Thiele\\ Humboldt-Universit\"at zu Berlin
}
\date{\today}


%%% LANGUAGE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% babel provides hyphenation patterns and translations of keywords like 'table
% of contents'
\usepackage[ngerman]{babel}

\usepackage{amsthm}
\newtheorem{theorem}{Satz}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]


%%% HYPERLINKS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% automatic generation of hyperlinks for references and URIs
\usepackage{hyperref}

%%% MATH %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% amsmath provides commands for type-setting mathematical formulas
\usepackage{amsmath}
% amssymb provides additional symbols
\usepackage{amssymb}
% HINT
% Use http://detexify.kirelabs.org/classify.html to find unknown symbols!

%%% COLORS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% define own colors and use colored text
\usepackage[pdftex,svgnames,hyperref]{xcolor}

%%% nice tables
\usepackage{booktabs}

%%% Code Listings %%%%%%%%%%%%%%%%
% provides commands for including code (python, latex, ...)
\usepackage{listings}
\definecolor{keywords}{RGB}{255,0,90}
\definecolor{comments}{RGB}{0,0,113}
\definecolor{red}{RGB}{160,0,0}
\definecolor{green}{RGB}{0,150,0}
\lstset{language=Python, 
        basicstyle=\ttfamily\small, 
        keywordstyle=\color{keywords},
        commentstyle=\color{comments},
        stringstyle=\color{red},
        showstringspaces=false,
        identifierstyle=\color{green},
        }

\usepackage{graphicx}
\usepackage{paralist}

\usepackage[style=authoryear, backend=biber,natbib=true]{biblatex}
\addbibresource{mapliteratur.bib}

% setting the font style for input und returns in description items
\newcommand{\initem}[2]{\item[\hspace{0.5em} {\normalfont\ttfamily{#1}} {\normalfont\itshape{(#2)}\/}]}
\newcommand{\outitem}[1]{\item[\hspace{0.5em} \normalfont\itshape{(#1)}\/]}
\newcommand{\bfpara}[1]{
	
	\noindent \textbf{#1:}\,}

\begin{document}

% generating the title page
\maketitle
\newpage
% generating the table of contents (requires to run pdflatex twice!)
\tableofcontents
\newpage

%%% BEGIN OF CONTENT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Einf\"uhrung in die Theorie}
	\subsection{Motivation und Problemstellung}

	
	\subsection{Theoretischer Hintergrund}
		\subsubsection{Lösen eines Gleichungssystems mit der LU Zerlegung}
	In der Linearen Algebra haben wir bereits zum Lösen von Gleichunssystemen den Gaußschen Algorithmus kennengelernt. Beim Durchführen des Gaußschen Algorithmus an eine Matrix $A$ wird diese Matrix in eine  oberen rechten Dreiecksmatrix mit Einsen auf der Hauptdiagonalen und einer unteren linken Dreicksmatrix zerlegt. Eine solche Zerlegung nennt man auch \textit{LU-Zerlegung}.
	\begin{definition}[LU-Zerlegung]
	Eine Zerlegung einer Matrix $A$ der Form $A=L\cdot U$ mit einer unteren linken Dreiecksmatrix mit Einsen auf der Hauptdiagonalen $L$ und eine oberen rechten Dreiecksmatrix $U$:
	\begin{align*}
	L=\begin{pmatrix}
	1&0&\cdots&0&0\\
	*&1&\cdots&0&0\\
	\vdots&\vdots&\ddots&\vdots&\vdots\\
	*&*&\cdots&0&0\\
	*&*&\cdots&*&1
	\end{pmatrix},
	U=\begin{pmatrix}
	*&*&\cdots&*&*\\
	0&*&\cdots&*&*\\
\vdots&\vdots&\ddots&\vdots&\vdots\\
	0&0&\cdots&*&*\\
	0&0&\cdots&0&*
	\end{pmatrix}
	\end{align*}
	heißt \textit{LU-Zerlegung}.
	\end{definition}
	\begin{theorem}
	Jede reguläre Matrix lässt sich LU-zerlegen mit 
	$$PA=LU$$
	wobei $P$ eine geeignete Permutationsmatrix ist. 
	\end{theorem}
	\begin{proof}
	Sei $A$ eine reguläre Matrix $A=(a_{i,j})$. Wir setzten $A^{(0)}:=A$. Dann gilt für $$L_1=\begin{pmatrix}
	
	1&0&\cdots&0&0\\
	-l_{21}&1&\cdots&0&0\\
	\vdots&\vdots&\ddots&\vdots&\vdots\\
	-l_{n2}&0&\cdots&0&1

	\end{pmatrix}	
	$$ mit $l_{i1}=\frac{a_{i1}^{(0)}}{a_{11}^{(0)}}$, dass
$$A^{(1)}:=L_1\cdot A^{(0)}$$ gilt mit 
$$A^{(1)}=\begin{pmatrix}
a_{11}^{(1)}&a_{12}^{(1)}&\cdots &a_{1n}^{(1)}\\
0&a_{22}^{(1)}&\cdots &a_{2n}^{(1)}\\
\vdots&\vdots&\ddots&\vdots\\
0&a_{n2}^{(1)}&\cdots & a_{nn}^{(1)}
\end{pmatrix}
	$$
	Im $i$-ten Schritt des Gauss-Algorithmus erhalten wir
	$$ A^{(i)} = L_iA^{(i-1)}$$
	mit
	$$ A^{(i)}=\begin{pmatrix}
	a_{11}^{(i)}&a_{12}^{(i)}&\cdots&a_{1i}^{(i)}&a_{1,i+1}^{(i)}&\cdots&a_{1n}^{(i)}\\
	0&a_{22}^{(i)}&\cdots&a_{2i}^{(i)}&a_{2,i+1}^{(i)}&\cdots&a_{2n}^{(i)}\\
	\vdots&\vdots&\ddots&\vdots&\vdots&&\vdots\\
	0&0&\cdots&a_{ii}^{(i)}&a_{i,i+1}^{(i)}&\cdots&a_{in}^{(i)}\\
	0&0&\cdots&0&a_{i+1,i+1}^{(i)}&\cdots&a_{i+1,n}^{(i)}\\
	\vdots&\vdots&&\vdots&\vdots&\ddots&\vdots\\
	0&0&\cdots&0&a_{n,i+1}^{(i)}&\cdots&a_{nn}^{(i)}
	\end{pmatrix}
	$$
	und $$L_1:=\begin{pmatrix}
	1&\cdots&0&0&0&\cdots&0\\
	\vdots&\ddots&\vdots&\vdots&\vdots&&\vdots\\
	0&\cdots&1&0&0&\cdots&0\\
	0&\cdots&0&1&0&\cdots&0\\
	0&\cdots&0&-l_{i+1,i}&1&\cdots&0\\
	\vdots&&\vdots&\vdots&\vdots&\ddots&\vdots\\
	0&\cdots&0&-l_{n,i}&0&\cdots&1\\
	\end{pmatrix}
	$$wobei $$l_{k,i}:=\frac{a_{k,i}^{(i-1)}}{a_{i,i}^{(i-1)}}$$
	Nach $n-1$ Schritten erhalten wir dann insgesamt
	$$A^{(n-1)}=L_{n-1}A^{(n-2)}=\cdots=L_{n-1}L_{n-2}\cdots L_{1}A^{(0)}\\$$
	und damit
	$$L_{1}^{-1}L_{2}^{-1}\cdots L_{n-1}^{-1}A^{(n-1)}=A^{(0)}$$
	Hierbei ist $$U:=A^{(n-1)}$$ eine obere Dreiecksmatrix und es lässt sich leicht nachrechnen, dass $$L:=L_{1}^{-1}L_{2}^{-1}\cdots L_{n-1}^{-1}=\begin{pmatrix}
	1&0&\cdots&0&0\\
	l_{21}&1&\cdots&0&0\\
	\vdots&\vdots&\ddots&\vdots&\vdots\\
	l_{n-1,1}&l_{n-1,2}&\cdots&1&0\\
	l_{n1}&l_{n2}&\cdots&l_{n,n-1}&1
	\end{pmatrix}
	$$ eine untere Dreiecksmatrix mit Einsen auf der Hauptdiagonalen ist.
	Damit haben wir schon unsere Zerlegung $$LU=A$$
	\end{proof}		
	
	\subsubsection{Pivotisierung}
	Um zu verhindern, dass beim Invertieren große Einträge in der $L$-Matrix stehen, die eventuell andere Einträge \textit{auslöscht} wollen wir die Matrizen $L_i$, die im $i$-ten Schritt des Gauss-Verfahrens entstehen, so wählen dass die \textit{Kondition} minimal wird.
	Für die \textit{Kondition} gilt:
	\begin{align*}
	cond_1(L_i)&=||L_i^{-1}||_1||L_i||_1\\
	&=\left(1+\sum_{k=i+1}^{m}|l_{ki}|\right)^2\\
	&=\left(1+\sum_{k=i+1}^{m}\left|\frac{a_{ki}^{(i-1)}}{a_{ii}^{(i-1)}}\right|\right)^2
	\end{align*}
	Wir wollen im $i$-ten Eliminationsschritt also unser \textit{Pivotelement} $a_{ii}$ möglichst groß
	wählen.
	
	Sei also $k^*$ so, dass
	$$ |a_{k^*i}^{(i-1)}|= \max_{k=1,...,n} |a_{ki}^{(i-1)}|$$
	
	Dazu tauschen wir die $i$-te Zeile mit der $k^*$-ten Zeile.
	Hierzu verwenden wir die Matrix $P$, die aus der Einheitsmatrix entsteht indem man die $i$-te und $k^*$-te Spalte tauscht.
	$$P_i=\begin{array}{cc}
	\begin{array}{c}
	\begin{pmatrix}	
	1&0&\cdots&0&\cdots&0&\cdots&0&0\\
	0&1&\cdots&0&\cdots&0&\cdots&0&0\\
	&&\ddots&\vdots&&\vdots&&&\\
	&&&0&&1&&&\\
	\vdots&\vdots&&\vdots&\ddots&\vdots&&\vdots&\vdots\\
	&&&1&&0&&&\\
	&&&\vdots&&\vdots&\ddots&&\\
	0&0&\cdots&0&\cdots&0&\cdots&1&0\\
	0&0&\cdots&0&\cdots&0&\cdots&0&1
	\end{pmatrix}
	\end{array}&\begin{array}{cc}
	&\\
	&\\
	&\\
	\leftarrow&i\text{-te Zeile}\\
	\\
	\leftarrow&k^*\text{-te Zeile}\\
	&\\
	&\\
	&\\
	\end{array}
	\end{array}	
	$$	
	
	Damit finden wir $$A^{(i)}=L_iP_iA^{(i-1)}$$ wobei $L_i$ optimal konditioniert ist.
	
	Wir erhalten also nach dem $(n-1)$-ten Eliminationsschritt.
	$$A^{(n-1)}=L_{n-1}P_{n-1}L_{n-2}P_{n-2}\cdots L_{1}P_{1}A^{(0)}$$

	Da $P_i$ jeweils sein eigenes Inverses ist, können wir folgendermaßen mit der Einheitsmatrix multiplizieren:
	$$A^{(n-1)}=L_{n-1}P_{n-1}L_{n-2}P_{n-2}\cdots L_{2}P_{2}L_{1}P_{2}P_{2}P_{1}A^{(0)}$$
	Man kann leicht sehen, dass $P_{2}L_{1}P_{2}=L_{1}$ gilt, und somit 
$$A^{(n-1)}=L_{n-1}P_{n-1}L_{n-2}P_{n-2}\cdots L_{2}L_{1}P_{2}P_{1}A^{(0)}.$$
Induktiv können wir so alle Permutationsmatrizen an den $L$ Matrizen vorbeischieben, sodass wir folgende Gleichung erhalten.
$$A^{(n-1)}=L_{n-1}L_{n-2}\cdots L_{1}P_{n-1}P_{n-2}\cdots P_{1}A^{(0)}.$$


	
	Mit $$L:=L_{1}^{-1}L_{2}^{-1}\cdots L_{n-1}^{-1}$$
	und $$P:=P_{n-1}P_{n-2}\cdots P_1$$ und $$A^{(n-1)}=U$$
	erhalten wir $$PA=LU$$
	\subsubsection{Beispielrechnung}
	Wir führen beispielhaft den obigen Algorithmus zur Bestummung der LU-Zerlegung einer Matrix an der folgen Matrix $A$ durch.
	$$A=A^{(0)}=\begin{pmatrix}
	2&4&-2\\
	4&9&-3\\
	-2&-3&7
	\end{pmatrix}$$
	Wir vertauschen zunächst die erste und zweite Zeile durch Multiplikation mit der Permutationsmatrix 
	$$P_1=\begin{pmatrix}
	0&1&0\\
	1&0&0\\
	0&0&1
	\end{pmatrix}$$
	Wir erhalten 
	$$P_1\cdot A=\begin{pmatrix}
	4&9&-3\\
	2&4&-2\\
	-2&-3&7
	\end{pmatrix}
$$ Nun eliminieren wir durch geeignete Wahl von $L_1$ die unteren Einträge der ersten Spalte. Wir setzten 
	$$A^{(1)}:=L_1P_1A^{(0)}=\begin{pmatrix}
	4&9&-3\\
	0&-\frac{1}{2	}&-\frac{1}{2	}\\
	0&\frac{3}{2}&\frac{11}{2}
	\end{pmatrix}, \text{ mit } L_1=\begin{pmatrix}
	1&0&0\\
	-\frac{1}{2}&0&0\\
	\frac{1}{2}&0&0
	\end{pmatrix}$$
	
	Wieder Pivotisieren wir
	
	$$P_2A^{(1)}=\begin{pmatrix}
	4&9&-3\\
	0&\frac{3}{2}&\frac{11}{2}\\
	0&-\frac{1}{2	}&-\frac{1}{2	}
	\end{pmatrix}, \text{ mit }
	P_2=\begin{pmatrix}
	1&0&0\\
	0&0&1\\
	0&1&0
	\end{pmatrix}
	$$
	
	und wir setzen 
	$$A^{(2)}:=L_2P_2A^{(1)}=\begin{pmatrix}
	4&9&-3\\
	0&\frac{3}{2}&\frac{11}{2}\\
	0&0&\frac{4}{3	}
	\end{pmatrix}, \text{ mit } L_2=\begin{pmatrix}
	1&0&0\\
	0&1&0\\
	0&\frac{1}{3}&1
\end{pmatrix}	
$$
Wir haben also mit 
	
	
\section{Implementierung}
	
Wir wollen später Gleichungssysteme mithilfe der LU-Zerlegung lösen und  dann \textit{Kondition}, die Anzahl der Nicht-Null-Einträge und den Fehler der Approximation im Vergleich zur exakten Lösung in unseren Experimenten genauer betrachten.
Hierzu haben wir drei Programme implementiert:

\subsection{\texttt{block\_matrix.py}}
Für unsere Blockmatrizen interessiert uns deren LU-Zerlegung, außerdem möchten wir in unseren Experimenten die \textit{Kondition} und \textit{Sparsity} vergleichen können.
Deshalb haben wir die Klasse \texttt{BlockMatrix} des Programms
\texttt{block\_matrix.py} um die folgenden Funktionen erweitert:

\subsubsection*{\texttt{get\_lu()}:}
Diese Funktion zerlegt unsere Matrix in eine orthogonale Matrix zur \textit{Pivorisierung}, eine untere linke Dreiecksmatrix mit Einsen auf der Hauptdiagonalen und eine obere rechte Dreiecksmatrix.
Wir verwenden dafür zunächst \texttt{get\_sparse()} um die Matrix zu erhalten, welche die entsprechende Dimension und Intervallzahl pro Dimension repräsentiert. Mit \texttt{todense()} ändern wir die Matrix in ein \textit{Numpy-Array}, sodass wir dann \texttt{scipy.linalg.lu()} verwenden können. Das liefert uns schon das Erwünschte.

\subsubsection*{\texttt{eval\_sparsity\_lu()}:}
\texttt{eval\_sparsity\_lu()} soll die absolute Anzahl an Nicht-Null-Einträgen der \textit{LU-Zerlegung} einer Matrix, sowie die relative Anzahl ausgeben. 
Es muss also zuerst die \textit{LU-Zerlegung} bestimmt werden. Hierfür können wir \texttt{get\_lu()} verwenden. Die Nicht-Null-Einträge von $L$ und $U$ lassen sich durch \texttt{numpy.count\_nonzero()} ermitteln. Um die absolute Anzahl zu erhalten addieren wir die beiden Werte, ziehen aber noch $(n-1)^d$ ab, denn wir möchten die Einsen auf der Hauptdiagonalen nicht mitzählen.
Der relative Wert berechnet sich dann, indem wir die absolute Anzahl durch die Zahl an Elementen der Koeffizientenmatrix ($=(n-1)^{2d}$) teilen.

\subsubsection*{\texttt{get\_cond()}:}
\texttt{get\_sparse()} bringt uns unsere Koeffizientenmatrix. Die \textit{Kondition} berechnet sich dann mit folgender Formel:
$$
cond(A)=||A^{-1}||_{\infty}||A||_{\infty}
$$
Die Bestimmung der Inversen und der Norm erfolgt mithilfe von 
\texttt{scipy.sparse.linalg}-Funktionen.

\subsection{\texttt{linear\_solvers.py}}
Mit diesem Programm kann man Gleichungen der Form $Ax=b$ lösen. Dies geschieht über eine \texttt{pivotisierte LU-Zerlegung}.

\subsubsection*{\texttt{solve\_lu()}:}
Diese Funktion benötigt als Input $p , l , u$ und $b$ und gibt uns die Lösung $x$ des Gleichungssystems wieder.
Wir können die Dreiecksform unserer Matrizen ausnutzen und $x$ durch \textit{Vorwärts- und Rückwertseinsetzen} bestimmen. Das Ganze wird dann durch \texttt{scipy.linalg.solve\_triangular()} umgesetzt.
Wir bestimmen zunächst $y$ aus
$$
Ly = P^{-1}b
$$
Da $P^{-1}$ eine orthogonale Matrix ist, können wir \texttt{numpy.transpose(p)} nutzen.
Im zweiten Schritt liefert uns
$$
Ux=y
$$
unsere Lösung $x$.

\subsection{\texttt{poisson\_problem.py}}
Wir wollen den Fehler der Approximation im Vergleich zur exakten Lösung vergleichen können. Dieses Programm erweitern wir deshalb um folgende Funktion:

\subsubsection*{\texttt{compute\_error()}:}
Hier wird der maximale absolute Fehler der Approximation an den Diskretisierungspunkten berechnet, bezüglich der \textit{Infinity-Norm}. Dazu nimmt die Funktion als Input die Dimension, die Anzahl an Intervallen pro Dimension, die exakte Lösung des \textit{Poisson-Problems} an den Diskretisierungspunkten und die Funktion welche das \textit{Poisson-Problem} löst.
Dafür gehen wir sukzessive die Diskretisierungspunkte durch, bestimmen dessen Koordinaten mithilfe von \texttt{inv\_idx} und erhalten mit $u(x)$ die exakte Lösung. 
Die \texttt{Infinity-Norm} der Differenz zur Approximierten Lösung gibt uns dann unseren Wert für den Fehler.
	
\section{Beschreibung der Experimente und Beobachtungen}

\section{Zusammenfassung}



\printbibliography

%%% END OF DOCUMENT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
